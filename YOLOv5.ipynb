{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6MPjfT5NrKQ"
      },
      "source": [
        "# Intelligent Applications of Deep Learning YOLOv5\n",
        "This notebook modified from https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount your google drive "
      ],
      "metadata": {
        "id": "OOOruywQbrgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "W5fVVC0SmOYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clone yolov5 on github"
      ],
      "metadata": {
        "id": "cpB4Pd6cbS7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone"
      ],
      "metadata": {
        "id": "4nHnnJUtbQXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cd to yolov5 repo\n",
        "yolov5_PATH=\"???/yolov5\"\n",
        "%cd {yolov5_PATH}"
      ],
      "metadata": {
        "id": "KEeYyQ2TcIDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Clone GitHub [repository](https://github.com/ultralytics/yolov5), install [dependencies](https://github.com/ultralytics/yolov5/blob/master/requirements.txt) and check PyTorch and GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG"
      },
      "source": [
        "%pip install -qr requirements.txt  # install\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()  # checks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY2VXXXu74w5"
      },
      "source": [
        "## 1. Train\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NcFxRcFdJ_O"
      },
      "source": [
        "# Train YOLOv5s on customize dataset\n",
        "# Yaml file should be put in yolov5/data\n",
        "YAML_NAME=\"???.yaml\"\n",
        "!python train.py --img 640 --batch 16 --epochs 30 --data {YAML_NAME} --weights yolov5s.pt --cache"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eq1SMWl6Sfn"
      },
      "source": [
        "## 2. Validate\n",
        "To show results by class use the `--verbose` flag."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X58w8JLpMnjH"
      },
      "source": [
        "# Validate YOLOv5s on val set\n",
        "# Weight path\n",
        "best_weight=\"???.pt\"\n",
        "!python val.py --weights {best_weight} --data vehicle.yaml --img 640 --half"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JnkELT0cIJg"
      },
      "source": [
        "## 3. Inference\n",
        "\n",
        "`detect.py` runs YOLOv5 inference on a variety of sources, downloading models automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases), and saving results to `runs/detect`. Example inference sources are:\n",
        "\n",
        "```shell\n",
        "python detect.py --source 0  # webcam\n",
        "                          img.jpg  # image \n",
        "                          vid.mp4  # video\n",
        "                          screen  # screenshot\n",
        "                          path/  # directory\n",
        "                          'path/*.jpg'  # glob\n",
        "                          'https://youtu.be/Zgi9g1ksQHc'  # YouTube\n",
        "                          'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zR9ZbuQCH7FX"
      },
      "source": [
        "# Output txt file normalized xywh (center_x, center_y, width, height) \n",
        "# Weight path\n",
        "best_weight=\"???.pt\"\n",
        "inference_image_dir=\"\"\n",
        "!python detect.py --weights {best_weight}  --source {inference_image_dir} --save-txt  --save-conf --save-crop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple OCR example"
      ],
      "metadata": {
        "id": "2g1JxqL_0Ad4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install easyocr"
      ],
      "metadata": {
        "id": "xlOByLf43HH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import easyocr\n",
        "from IPython.display import Image,display\n",
        "\n",
        "# the path of image\n",
        "image_file_path=''\n",
        "print(f\"img name: {os.path.basename(image_file_path)}\")\n",
        "display(Image(image_file_path))\n",
        "reader = easyocr.Reader([\"en\"])\n",
        "\n",
        "result = reader.readtext(image_file_path,detail=0)\n",
        "print(f\"OCR result: {result}\")"
      ],
      "metadata": {
        "id": "o2lkBhI93PRX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}